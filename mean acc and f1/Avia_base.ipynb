{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import global_var\n",
    "import augment\n",
    "import dataset\n",
    "import modeling\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_cl_nm = pd.read_csv('train.csv')\n",
    "test_nm = pd.read_csv('test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_cl_nm.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, y_train = [], []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for index, row in tqdm(train_cl_nm.iterrows()):\n",
    "    im = cv2.imread(global_var.TRAIN_DIR + row['filename'] + '.png')\n",
    "    X_train.append(im)\n",
    "    y_train.append(row['sign'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.array(X_train)\n",
    "y = np.array(y_train).reshape(-1,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net = models.resnet18(pretrained=True).to(global_var.DEVICE)  # загружаем предобученную на ImageNet resnet152 сразу на GPU\n",
    "fc_inputs = net.fc.in_features\n",
    "\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 1)\n",
    ").to(global_var.DEVICE)\n",
    "net.aux_logits=False\n",
    "\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in net.fc.parameters():  # включаем последний слой (классификатор)\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in net.layer1.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in net.layer2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in net.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in net.layer4.parameters():\n",
    "    param.requires_grad = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stratified kfold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model, device, loss_fn, optimizer, train_loader, val_loader, num_epoch, n_fold):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    acc = []\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        epoch_train_losses = []\n",
    "        model.train(True)\n",
    "        for X_train, y_train in tqdm(train_loader):\n",
    "            # Посчитаем предсказание и лосс\n",
    "            X_train = X_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            y_pred = model(X_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            del y_pred\n",
    "\n",
    "            # зануляем градиент\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "\n",
    "            # ОБНОВЛЯЕМ веса\n",
    "            optimizer.step()\n",
    "\n",
    "            # Запишем число (не тензор) в наши батчевые лоссы\n",
    "            epoch_train_losses.append(loss.item())   \n",
    "                    \n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        \n",
    "        # Теперь посчитаем лосс на вал\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            epoch_test_losses = []\n",
    "            epoch_acc = []\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                y_pred = model(X_val)\n",
    "                loss = loss_fn(y_pred, y_val)\n",
    "            \n",
    "                epoch_test_losses.append(loss.item())\n",
    "                y_pred = y_pred.sigmoid().detach().cpu().numpy()\n",
    "                y_pred = (y_pred>=0.5).astype(int)\n",
    "                epoch_acc.append(accuracy_score(y_val.cpu(), y_pred))\n",
    "                del y_pred\n",
    "\n",
    "            test_losses.append(np.mean(epoch_test_losses))\n",
    "            acc.append(np.mean(epoch_acc))\n",
    "            \n",
    "            torch.save(model.state_dict(), f'epoch_{i}_fold_{n_fold}.pth')  # сохраняем веса эпох\n",
    "\n",
    "            print(\n",
    "                'Train loss =', train_losses[-1],\n",
    "                'Val loss =', test_losses[-1],\n",
    "                'Val accuracy score =', acc[-1]\n",
    "            )\n",
    "        if i == 5:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr']*0.8\n",
    "            \n",
    "    return train_losses, test_losses, acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = []\n",
    "for index, row in tqdm(test_nm.iterrows()):\n",
    "    im = cv2.imread(global_var.TEST_DIR + row['filename'] + '.png')\n",
    "    test.append(im)\n",
    "X_test = np.array(test)\n",
    "inference_data = dataset.Airplane_test(X_test, augmentation = augment.valid_augmentation())\n",
    "\n",
    "# dataloaders - с помощью нашего класса датасета сэмплируют данные в батчи\n",
    "inference_dataloader = DataLoader(inference_data, batch_size=global_var.BATCH_SIZE, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Обучение\n",
    "#\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "n_fold = 0\n",
    "y_preds = np.zeros(1000)\n",
    "best_epochs = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    print(\"Fold\", n_fold)\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_valid, y_valid = X[test_index], y[test_index]\n",
    "    \n",
    "    \n",
    "    train_data = dataset.Airplane(X_train, y_train, augmentation=augment.train_augmentation())\n",
    "    val_data = dataset.Airplane(X_valid, y_valid, augmentation=augment.alid_augmentation())\n",
    "    trainloader = DataLoader(train_data, batch_size=global_var.BATCH_SIZE, shuffle=False)  \n",
    "    valloader = DataLoader(val_data, batch_size=global_var.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    net = models.resnet18(pretrained=True).to(global_var.DEVICE)\n",
    "    fc_inputs = net.fc.in_features\n",
    "\n",
    "    net.fc = nn.Sequential(\n",
    "        nn.Linear(fc_inputs, 1)\n",
    "    ).to(global_var.DEVICE)\n",
    "    net.aux_logits=False\n",
    "    optimizer = optim.Adam(net.parameters(), lr = 0.00075)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_losses, val_losses, roc_score = train_model(net, device, criterion, optimizer, trainloader, valloader, 10,n_fold)\n",
    "    best_epochs.append(f'epoch_{np.array(roc_score).argmax()}_fold_{n_fold}.pth')\n",
    "    net.load_state_dict(torch.load(f'epoch_{np.array(roc_score).argmax()}_fold_{n_fold}.pth'))\n",
    "    y_preds += modeling.inference_fn(net, inference_dataloader, global_var.DEVICE).reshape(-1)\n",
    "    n_fold+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_epochs"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "af0c9cac6af363f277969eb9c7b3f0bdd35b60582a1c4885676e4f1473755872"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}