{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import albumentations as albu\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import cv2\n",
    "\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')  # включаем поддержку GPU\n",
    "\n",
    "%matplotlib inline\n",
    "device"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dir = 'avia-train/avia-train/'\n",
    "test_dir = 'avia-test/avia-test/'\n",
    "\n",
    "images_train_filenames =  [f for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
    "images_test_filenames =  [f for f in listdir(test_dir) if isfile(join(test_dir, f))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_cl_nm = pd.read_csv('train.csv')\n",
    "test_nm = pd.read_csv('test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_cl_nm.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def convert_image_to_array(img, image_size):\n",
    "    try:\n",
    "        return cv2.resize(img, (image_size, image_size), interpolation = cv2.INTER_AREA)\n",
    "    except BaseException as e:\n",
    "        print('Error!')\n",
    "        print(e)\n",
    "        plt.imshow(np.array(img) / 255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_size = 128"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, y_train = [], []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for index, row in tqdm(train_cl_nm.iterrows()):\n",
    "    im = cv2.imread(train_dir + row['filename'] + '.png')\n",
    "#     im_array = convert_image_to_array(im, image_size=image_size)\n",
    "    X_train.append(im)\n",
    "    y_train.append(row['sign'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.array(X_train)\n",
    "y = np.array(y_train).reshape(-1,1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 256, test_size = 0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_augmentation():\n",
    "    transform = [\n",
    "        albu.Resize(height=image_size, width=image_size, p=1),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.HorizontalFlip(p = 0.7),\n",
    "                albu.VerticalFlip(p = 0.2),\n",
    "                albu.RandomRotate90(p = 0.1),\n",
    "            ],\n",
    "            p = 0.7\n",
    "        ),\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.GaussNoise(p=0.5),\n",
    "                albu.RandomGamma(p=0.2),\n",
    "                albu.RandomBrightnessContrast(p=0.3),\n",
    "            ],\n",
    "            p = 0.4\n",
    "        ),\n",
    "        albu.ShiftScaleRotate(\n",
    "            shift_limit=0.002, scale_limit=0.2, rotate_limit=180,\n",
    "            p=0.1\n",
    "        )\n",
    "    ]\n",
    "    return albu.Compose(transform, p = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def valid_augmentation():\n",
    "    transform = [\n",
    "        albu.Resize(height=image_size, width=image_size, p=1),\n",
    "    ]\n",
    "    return albu.Compose(transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Airplane(Dataset):\n",
    "    def __init__ (self, data, labels, augmentation = None):\n",
    "        self.X = data\n",
    "        self.y = labels\n",
    "        self.aug = augmentation\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        img = self.X[i]\n",
    "        if self.aug:\n",
    "            sample = np.array(self.aug(image=img))\n",
    "        label = self.y[i]\n",
    "        return torch.tensor(np.moveaxis(sample.reshape(-1)[0]['image'], -1, 0), dtype=torch.float), torch.tensor(label, dtype=torch.float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "net = models.resnet18(pretrained=True).to(device)  # загружаем предобученную на ImageNet resnet152 сразу на GPU\n",
    "fc_inputs = net.fc.in_features\n",
    "\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 1)\n",
    ").to(device)\n",
    "net.aux_logits=False\n",
    "\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in net.fc.parameters():  # включаем последний слой (классификатор)\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in net.layer1.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in net.layer2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in net.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in net.layer4.parameters():\n",
    "    param.requires_grad = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stratified kfold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model, device, loss_fn, optimizer, train_loader, val_loader, num_epoch, n_fold):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    acc = []\n",
    "\n",
    "    for i in range(num_epoch):\n",
    "        epoch_train_losses = []\n",
    "        model.train(True)\n",
    "        for X_train, y_train in tqdm(train_loader):\n",
    "            # Посчитаем предсказание и лосс\n",
    "            X_train = X_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            y_pred = model(X_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            del y_pred\n",
    "\n",
    "            # зануляем градиент\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "\n",
    "            # ОБНОВЛЯЕМ веса\n",
    "            optimizer.step()\n",
    "\n",
    "            # Запишем число (не тензор) в наши батчевые лоссы\n",
    "            epoch_train_losses.append(loss.item())   \n",
    "                    \n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        \n",
    "        # Теперь посчитаем лосс на вал\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            epoch_test_losses = []\n",
    "            epoch_acc = []\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                y_pred = model(X_val)\n",
    "                loss = loss_fn(y_pred, y_val)\n",
    "            \n",
    "                epoch_test_losses.append(loss.item())\n",
    "                y_pred = y_pred.sigmoid().detach().cpu().numpy()\n",
    "                y_pred = (y_pred>=0.5).astype(int)\n",
    "                epoch_acc.append(accuracy_score(y_val.cpu(), y_pred))\n",
    "                del y_pred\n",
    "\n",
    "            test_losses.append(np.mean(epoch_test_losses))\n",
    "            acc.append(np.mean(epoch_acc))\n",
    "            \n",
    "            torch.save(model.state_dict(), f'epoch_{i}_fold_{n_fold}.pth')  # сохраняем веса эпох\n",
    "\n",
    "            print(\n",
    "                'Train loss =', train_losses[-1],\n",
    "                'Val loss =', test_losses[-1],\n",
    "                'Val accuracy score =', acc[-1]\n",
    "            )\n",
    "        if i == 5:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = g['lr']*0.8\n",
    "            \n",
    "    return train_losses, test_losses, acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in dataloader:\n",
    "\n",
    "            outputs = model(inputs.to(device))\n",
    "            y_pred = outputs.sigmoid().detach().cpu().numpy()\n",
    "\n",
    "            preds.append(y_pred)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    \n",
    "    return preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Airplane_test(Dataset):\n",
    "    def __init__ (self, data, augmentation = None):\n",
    "        self.X = data\n",
    "        self.aug = augmentation\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        img = self.X[i]\n",
    "        if self.aug:\n",
    "            sample = np.array(self.aug(image=img))\n",
    "        return torch.tensor(np.moveaxis(sample.reshape(-1)[0]['image'], -1, 0), dtype=torch.float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = []\n",
    "for index, row in tqdm(test_nm.iterrows()):\n",
    "    im = cv2.imread(test_dir + row['filename'] + '.png')\n",
    "#     im_array = convert_image_to_array(im, image_size=image_size)\n",
    "    test.append(im)\n",
    "# for i in range(len(test)):\n",
    "#     if test[i].shape != (image_size, image_size, 3):\n",
    "#         test[i] = test[i][:,:,:3]\n",
    "X_test = np.array(test)\n",
    "inference_data = Airplane_test(X_test, augmentation = valid_augmentation())\n",
    "\n",
    "# dataloaders - с помощью нашего класса датасета сэмплируют данные в батчи\n",
    "BATCH_SIZE = 128\n",
    "inference_dataloader = DataLoader(inference_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Обучение\n",
    "#\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "n_fold = 0\n",
    "y_preds = np.zeros(1000)\n",
    "best_epochs = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    print(\"Fold\", n_fold)\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_valid, y_valid = X[test_index], y[test_index]\n",
    "    \n",
    "    \n",
    "    train_data = Airplane(X_train, y_train, augmentation=train_augmentation())\n",
    "    val_data = Airplane(X_valid, y_valid, augmentation=valid_augmentation())\n",
    "    BATCH_SIZE = 128\n",
    "    trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "    valloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    net = models.resnet18(pretrained=True).to(device)\n",
    "    fc_inputs = net.fc.in_features\n",
    "\n",
    "    net.fc = nn.Sequential(\n",
    "        nn.Linear(fc_inputs, 1)\n",
    "    ).to(device)\n",
    "    net.aux_logits=False\n",
    "    optimizer = optim.Adam(net.parameters(), lr = 0.00075)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_losses, val_losses, roc_score = train_model(net, device, criterion, optimizer, trainloader, valloader, 10,n_fold)\n",
    "    best_epochs.append(f'epoch_{np.array(roc_score).argmax()}_fold_{n_fold}.pth')\n",
    "    net.load_state_dict(torch.load(f'epoch_{np.array(roc_score).argmax()}_fold_{n_fold}.pth'))\n",
    "    y_preds += inference_fn(net, inference_dataloader, device).reshape(-1)\n",
    "    n_fold+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(train_losses, label = 'Train loss')\n",
    "plt.plot(val_losses, label = 'Val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(roc_score, label='ROC score')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('score')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_epochs"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "af0c9cac6af363f277969eb9c7b3f0bdd35b60582a1c4885676e4f1473755872"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}